
# LLMOps Pipeline â€“ Anime Recommender ğŸŒ

A production-ready **LLMOps** project demonstrating an **end-to-end AI-powered recommendation pipeline** â€” from data processing to vector search, LLM integration, and scalable deployment via **Docker** and **Kubernetes**.

This project uses **LangChain**, **ChromaDB**, **Hugging Face embeddings**, and **Groq LLM** to deliver **personalized anime recommendations** via a **Streamlit** web app.

---

## ğŸ“Œ Features

* ğŸ¯ **Personalized Recommendations** â€“ Tailored anime suggestions based on user preferences.
* ğŸ” **Semantic Search** â€“ Vector similarity matching for accurate results.
* ğŸš€ **Interactive UI** â€“ Built with Streamlit.
* ğŸ¤– **LLM-Powered** â€“ Uses Groq LLM with custom prompt templates.
* ğŸ“Š **Vector Database** â€“ Efficient retrieval using ChromaDB.
* â˜ **Cloud-Ready** â€“ Deployable with Docker and Kubernetes.
* ğŸ“ˆ **Monitoring** â€“ Optional Grafana Cloud setup for Kubernetes metrics.

---

## ğŸ“‚ Project Structure

```
llmops-pipeline/
â”œâ”€â”€ app/                      # Streamlit web application
â”œâ”€â”€ config/                   # API keys and environment configs
â”œâ”€â”€ data/                     # Anime datasets
â”œâ”€â”€ pipeline/                 # Main recommendation pipeline
â”œâ”€â”€ src/                      # Data loader, vector store, recommender, prompts
â”œâ”€â”€ utils/                    # Logging & custom exceptions
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package setup
â”œâ”€â”€ Dockerfile                # For containerization
â”œâ”€â”€ llmops-k8s.yaml           # Kubernetes deployment file
â””â”€â”€ README.md                 # This file
```

---

## ğŸ”§ 1. Local Setup

### **Clone the Repository**

```bash
git clone https://github.com/0Xuser100/AnimeRecommender.git
cd AnimeRecommender
```

### **Create and Activate a Virtual Environment**

```bash
# Create venv
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Mac/Linux)
source venv/bin/activate
```

### **Install Dependencies**

```bash
pip install --upgrade pip
pip install -e .
```

### **Set Environment Variables**

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key
HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_token
```

### **Run Locally**

```bash
streamlit run app/app.py
```

Access the app at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ³ 2. Run with Docker

### **Build Docker Image**

```bash
docker build -t llmops-app:latest .
```

### **Run Container**

```bash
docker run -p 8501:8501 --env-file .env llmops-app:latest
```

Visit: [http://localhost:8501](http://localhost:8501)

---

## â˜¸ 3. Deploy on Kubernetes (Minikube / GKE)

### **Start Minikube**

```bash
minikube start
```

### **Point Docker to Minikube**

```bash
# Linux / Mac:
eval $(minikube docker-env)

# Windows (PowerShell):
& minikube -p minikube docker-env | Invoke-Expression

# Windows (Command Prompt):
@FOR /f "tokens=*" %i IN ('minikube -p minikube docker-env') DO @%i
```

### **Build Image for Minikube**

```bash
docker build -t llmops-app:latest .
```

### **Create Secrets**

```bash
kubectl create secret generic llmops-secrets \
  --from-literal=GROQ_API_KEY="your_groq_key" \
  --from-literal=HUGGINGFACEHUB_API_TOKEN="your_hf_token"
```

### **Apply Kubernetes Manifest**

```bash
kubectl apply -f llmops-k8s.yaml
```

### **Access Service**

```bash
minikube tunnel
# In another terminal:
kubectl port-forward svc/llmops-service 8501:80 --address 0.0.0.0
```

Open: [http://<external-ip>:8501](http://<external-ip>:8501)

---

## ğŸ“Š 4. Optional: Grafana Cloud Monitoring

1. Create a **Grafana Cloud** account.
2. Install **Helm** and add the Grafana repo:

   ```bash
   helm repo add grafana https://grafana.github.io/helm-charts
   helm repo update
   ```
3. Deploy Kubernetes monitoring charts with:

   ```bash
   helm upgrade --install grafana-k8s-monitoring grafana/k8s-monitoring \
     --namespace monitoring --create-namespace --values values.yaml
   ```
4. View Kubernetes metrics in Grafana dashboards.

---

## ğŸ’¡ Example Queries

* `"light hearted anime with school settings"`
* `"dark fantasy anime with complex storylines"`
* `"romantic comedy anime similar to Your Name"`

---

## ğŸ›  Tech Stack

* **LangChain** â€“ LLM orchestration
* **ChromaDB** â€“ Vector store
* **Hugging Face** â€“ Embeddings
* **Groq LLM** â€“ Fast inference
* **Streamlit** â€“ Frontend
* **Docker + Kubernetes** â€“ Deployment
* **Grafana** â€“ Monitoring

---

## ğŸ‘¨â€ğŸ’» Author

**Mahmoud Abdulhamid**

